\section{EXISTING WAYS TO SOLVE SCHRÖDINGER EQUATION FOR HYDROGEN ATOM}

\subsection{Analytical Solution}

The potential of exact solutions is significantly constrained by the rapidly escalating complexity introduced by each additional body in the system. Despite the limitations, the existing methods remain the pinnacle of precision in quantum mechanics.

Providing an analytical solution offers the opportunity to verify the accuracy of numerical solutions, making it the most precise result that can be obtained. However, the number of exact solutions is limited due to the exponentially increasing complexity introduced by each additional body in the system. This paragraph will not contain any derivations. However, they are available in many standard texts, such as Kołos' \textit{Quantum Chemistry}.

A key outcome of these derivations is the set of hydrogen-like real wavefunctions \cite{kolos1978}. These include the following:

\begin{equation}
	\label{eq211}
	\begin{aligned}
		& 1s = N_{1s}e^{\frac{-Zr}{a_0}} \\
		& 2s = N_{2s}e^{\frac{-Zr}{2a_0}}(2 - \frac{Zr}{a_0}) \\
		& 2p_x =  N_{2p}e^{\frac{-Zr}{2a_0}}x \\
		& 2p_y =  N_{2p}e^{\frac{-Zr}{2a_0}}y \\
		& 2p_z =  N_{2p}e^{\frac{-Zr}{2a_0}}z \\		
		& 3s = N_{3s}e^{\frac{-Zr}{3a_0}}(27 - 18\frac{Zr}{a_0} + 2\frac{Z^2r^2}{a^2_0}) \\
		& 3p_x =  N_{3p}e^{\frac{-Zr}{3a_0}}(6-\frac{Zr}{a_0})x \\
		& 3p_y =  N_{3p}e^{\frac{-Zr}{3a_0}}(6-\frac{Zr}{a_0})y \\
		& 3p_z =  N_{3p}e^{\frac{-Zr}{3a_0}}(6-\frac{Zr}{a_0})z \\
		& 3d_{3z^2-r^2} =  N_{3d}e^{\frac{-Zr}{3a_0}}(3z^2-r^2) \\
		& 3d_{xy} =  2\sqrt{3}N_{3d}e^{\frac{-Zr}{3a_0}}xy \\
		& 3d_{xz} =  2\sqrt{3}N_{3d}e^{\frac{-Zr}{3a_0}}xz \\
		& 3d_{yz} =  2\sqrt{3}N_{3d}e^{\frac{-Zr}{3a_0}}yz \\
		& 3d_{x^2=y^2} =  \sqrt{3}N_{3d}e^{\frac{-Zr}{3a_0}}(x^2-y^2) \\
	\end{aligned}
\end{equation}

\noindent where

\(N_{1s}, N_{2s}... \) : normalization constants for specific orbital

\(a_0 \) : Bohr radius

\(Z \) : the number of protons in the nucleus, in the case of hydrogen atom $Z$, is equal to 1

\(e \) : Euler's constant

\(x,y,z \) : the distances from the origin of the coordinate system along their respective axis

\(r \) : the distance from the origin of the coordinate system

These functions, when discretized, provide a good initial guess for numerical algorithms implemented in this thesis, especially when the algorithm exhibits unclear divergence when tested with randomly generated vectors. Moreover, the Bohr-Schrödinger energy formula, derived from analytical solutions:

\begin{equation}
	E_n = -\frac{1}{2n^2}, \quad n \in \mathbb{N}
\end{equation}

\noindent offers a benchmark for expected energy values, enabling quantitative validation of numerical results.

Analytical solutions are limited to simple systems such as free particles, particles in a box, harmonic oscillators, rigid rotors, or the hydrogen atom eigen. They fail for multi-electron atoms due to electron-electron interactions and cannot handle external perturbations like electric or magnetic fields. These constraints have led to the development of new, approximate methods for describing complex quantum systems.
\subsection{Fundamental approximate methods}
\subsubsection{Variational Method}
The variational method's foundation is the variational principle, which states that:
\begin{equation}
	\langle E \rangle \geqslant E_1
\end{equation}

\noindent for any normalized trial wavefunctions That means that the set of all eigenvalues is bounded below by $E_1$, the actual ground state energy. This principle applies to systems with finite dimensions, such as atoms, molecules, and crystals. These functions are often referred to as trial wavefunctions or \textit{ansatz} in classic German literature on quantum mechanics.

Moreover, if the variational function is orthogonal to the exact solutions of the Schrödinger equation corresponding to all states with lower energy than the target state, the variational principle remains valid \cite{ideas_of_qc}. This is particularly relevant to this thesis, as excited states were calculated by enforcing orthogonality to previously determined solutions.

A variational method was created based on the variational principle. By selecting a trial wavefunction $\psi_{trial}$, one can compute the approximate energy using Rayleigh's quotient:

\begin{equation} E_{\text{approx}} = \frac{\langle \psi_{\text{trial}} | \hat{H} | \psi_{\text{trial}} \rangle}{\langle \psi_{\text{trial}} | \psi_{\text{trial}} \rangle}. \end{equation}

Since the $\psi_{trial}$ comprises of variables \textbf{x} and parameters \textbf{c}, the task is to minimize the $E$  by fine-tuning the values of parameter vector \textbf{c}, that is finding parameter values, for which


\begin{equation} 
	\frac{\partial E(\textbf{c})}{\partial \textbf{c}} = 0
\end{equation}

Problems arise when a wavefunction has many local minima and saddle points. Still, the closer the first trial wavefunction is to the real one, the greater the probability of finding the global minimum \cite{IzaacWang2018ComputationalQM}.

\subsubsection{Perturbation theory}

Perturbation theory starts with a simple, analytically solvable system in which the Hamiltonian operator is $\hat{H_0}$. The perturbation $\lambda \hat{H'}$ is added to that system, assuming that the perturbation is small compared to the known system. The parameter $\lambda$ controls the perturbation size and is thus of small value.

\begin{equation}
	\hat{H} = \hat{H_0} + \lambda \hat{H'}
\end{equation}

This method provides a way to calculate corrections to the energy levels and wavefunctions of the unperturbed system as a power series in $\lambda$. The first-order correction to the energy accounts for the direct effect of the perturbation, while second-order corrections include contributions from the coupling between different states. Higher-order corrections can be included for greater accuracy, though they become increasingly complex.

In quantum chemistry, perturbation theory is widely applied in methods like Møller-Plesset perturbation theory (MPn), where the Hartree-Fock solution is treated as the unperturbed system, and electron correlation is introduced as a perturbation. For example, MP2 (second-order perturbation theory) is a common method used to improve upon Hartree-Fock calculations for molecular energies.

The advantages of perturbation theory are its conceptual simplicity and efficiency for systems where the perturbation is small relative to the unperturbed Hamiltonian. The series may fail to converge or provide inaccurate results though, if the perturbation is too large or the unperturbed system poorly represents the true system. Still, perturbation theory is a well-established tool in quantum chemistry. It offers a balance between computational cost and accuracy. It is frequently used to calculate molecular properties, analyze spectroscopic transitions, and benchmark more complex computational methods \cite{ideas_of_qc}.

\subsection{Featured existing implementations of approximate methods}

\subsubsection{Hartree-Fock (HF) Method}

The Hartree-Fock (HF) method is a fundamental approximation method in quantum chemistry used to calculate the electronic structure of atoms, molecules, and solids. At its core, the Hartree-Fock method assumes that the total wavefunction of a multi-electron system can be approximated as a single Slater determinant, which ensures compliance with the Pauli exclusion principle by maintaining the wavefunction's antisymmetry. This determinant is constructed from a set of one-electron wavefunctions, or orbitals, which are iteratively optimized to minimize the system's total energy.

The HF method replaces the many-body electron-electron interaction with an average potential, known as the mean-field approximation. Each electron is considered to move in the average field created by all other electrons, simplifying the computational complexity. The central equations called the Hartree-Fock equations, are derived from the variational principle and solved iteratively using methods such as the self-consistent field (SCF) procedure. 

The HF method does not take into account the electron co-relation. This limitation often leads to overestimated total energies, although trends in relative energies, such as bond energies, are often accurate. More advanced methods, such as Møller-Plesset perturbation theory (MP2) and Coupled Cluster theory, are built on HF to include electron correlation effects.

Despite its limitations, the Hartree-Fock method remains a cornerstone of quantum chemistry. Its simplicity, efficiency, and conceptual clarity make it an essential tool for understanding electronic structures, benchmarking more sophisticated methods, and modeling molecular properties \cite{thijssen2007}.

\subsubsection{Finite-Difference Methods}

Finite Difference Methods (FDM) offer a numerical framework to solve the Schrödinger equation for molecular and atomic systems; by discretizing the spatial domain into a finite grid and approximating derivatives using finite differences, FDM transforms the continuous differential equations into algebraic systems that can be solved computationally.

FDM scales well to larger systems when implemented on modern hardware, especially GPUs, which can parallelize the computations over large grids. Another advantage of FDM is its simplicity and flexibility. It is especially effective for educational purposes and research on confined systems, low-dimensional structures, and exploratory studies. With advancements in hardware acceleration and numerical optimization, FDM continues to evolve as a practical approach for solving quantum mechanical problems \cite{IzaacWang2018ComputationalQM}.

\subsubsection{Machine Learning Approach}

Lastly, another interesting emerging method was published in 2020 in a Nature article, proposing a machine-learning approach to solving time-independent Schr{\"o}dinger equations, which solves systems with up to 30 electrons. This emerging approach holds great promise for the future of quantum mechanics research. As noted in previous sections, modern quantum chemistry methods balance accuracy with associated computational costs. A common practice is representing wave functions by a Slater matrix, which contains a linear combination of Slater determinants. One of the ways to lessen the computational burden is to use stochastic methods, which sample those determinant spaces. The work by Choo et al. contains a suggestion that the use of neural networks may have the potential of reducing the number of required determinants \cite{choo}.

The paper introduces PauliNet, a deep-learning-based quantum Monte Carlo \textit{ansatz} designed to replace traditional, rigid functional forms like standard Jastrow factors and backflow transformations with more flexible, trainable neural networks to further Choo's idea. This approach directly incorporates well-established quantum-chemical principles -- such as multideterminant Slater expansions, Jastrow factors, backflow transformations, and proper electron-electron cusp conditions -- into the neural network architecture, ensuring physical validity and efficient, robust optimization. Demonstrations on various molecular systems show significantly improved accuracy over existing wavefunction methods, achieving high precision with orders of magnitude fewer determinants. With an asymptotic scaling of $O(N^4)$, the proposed framework is expected to handle much larger and more complex systems with current high-accuracy techniques, as evidenced by its successful calculation of the transition-state energy in a 28-electron cyclobutadiene molecule -— an achievement previously limited to highly specialized methods \cite{hermann_deep-neural-network_2020}.

